{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAwlAGZL00Et",
        "outputId": "d218e8d6-644e-4952-bb04-5575381a7e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('/content/drive/My Drive/train1.csv')  # Replace 'your_data.csv' with your dataset path\n",
        "X = data['comment_text']\n",
        "y = data['identity_hate']\n",
        "\n",
        "# data = pd.read_csv('/kaggle/input/dataset101/HateSpeechDataset.csv')  # Replace 'your_data.csv' with your dataset path\n",
        "# X = data['Content']\n",
        "# y = data['Label']\n",
        "\n",
        "\n",
        "#three labels # hatespeech,ofensive,neither\n",
        "# trial with other dataset with 2 labels 1 for offensive and 0 for non offensive"
      ],
      "metadata": {
        "id": "HzFwS6Km0_rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gKZOI1dZ_Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYSo03n1Z_Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zg-4wAJ6YS44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0YowiEi1I91",
        "outputId": "dd741c60-d1a0-47be-eae8-1807cec9075b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "223549"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "t4ogZoi_1M2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Assuming you have NLTK installed, if not, install it using:\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to preprocess text data\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Remove special characters and punctuation\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
        "    # Join the words back into a string\n",
        "    text = ' '.join(filtered_text)\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "# Model training and evaluation steps..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUM2A0d41R9P",
        "outputId": "caf18698-6ace-4a0d-8758-b64cdf9b5713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_preprocessed = X_train.apply(preprocess_text)\n",
        "X_test_preprocessed = X_test.apply(preprocess_text)"
      ],
      "metadata": {
        "id": "RfYvTPD51Xxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning and preprocessing\n",
        "\n",
        "\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_preprocessed)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test_preprocessed)"
      ],
      "metadata": {
        "id": "r1JAkoZk1-dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train Decision Tree\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(X_train_tfidf, y_train)\n",
        "dt_preds = dt_classifier.predict(X_test_tfidf)\n",
        "dt_accuracy = accuracy_score(y_test, dt_preds)"
      ],
      "metadata": {
        "id": "_ar2Kt232Mws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c34mzwBc2eoV",
        "outputId": "a120c19e-be46-4311-f48b-9bbbb97c41a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9896891075821964"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate Accuracy\n",
        "dt_accuracy = accuracy_score(y_test, dt_preds)\n",
        "\n",
        "# Calculate Precision\n",
        "dt_precision = precision_score(y_test, dt_preds, average='weighted')\n",
        "\n",
        "# Calculate Recall\n",
        "dt_recall = recall_score(y_test, dt_preds, average='weighted')\n",
        "\n",
        "# Calculate F1 Score\n",
        "dt_f1_score = f1_score(y_test, dt_preds, average='weighted')\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Decision Tree Classifier Metrics:\")\n",
        "print(\"Accuracy:\", dt_accuracy)\n",
        "print(\"Precision:\", dt_precision)\n",
        "print(\"Recall:\", dt_recall)\n",
        "print(\"F1 Score:\", dt_f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-4FuPbx3CyG",
        "outputId": "16e323c6-224b-4326-db9a-aa571a495074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier Metrics:\n",
            "Accuracy: 0.9896891075821964\n",
            "Precision: 0.9882971149615107\n",
            "Recall: 0.9896891075821964\n",
            "F1 Score: 0.9889172825319892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AcNA_tZfCUzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Calibrate the classifier to get probability estimates\n",
        "calibrated_classifier = CalibratedClassifierCV(dt_classifier, method='sigmoid', cv='prefit')\n",
        "calibrated_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Get the predicted probabilities for the test set\n",
        "probabilities = calibrated_classifier.predict_proba(X_test_tfidf)\n",
        "\n",
        "# Calculate log loss\n",
        "dt_log_loss = log_loss(y_test, probabilities)\n",
        "\n",
        "# Print the log loss\n",
        "print(\"Log Loss for Decision Tree Classifier:\", dt_log_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4uuoqe63JQG",
        "outputId": "f49d4ec4-d293-4c4e-d598-ea0d6e399aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Loss for Decision Tree Classifier: 0.08962400806489855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assume these are the best parameters found from grid search\n",
        "best_params = {\n",
        "    'n_estimators': 100,\n",
        "    'max_depth': 10,\n",
        "    'min_samples_split': 2,\n",
        "    'min_samples_leaf': 1\n",
        "}\n",
        "\n",
        "# Create a Random Forest classifier with the best parameters\n",
        "best_rf_model = RandomForestClassifier(\n",
        "    n_estimators=best_params['n_estimators'],\n",
        "    max_depth=best_params['max_depth'],\n",
        "    min_samples_split=best_params['min_samples_split'],\n",
        "    min_samples_leaf=best_params['min_samples_leaf']\n",
        ")\n",
        "\n",
        "# Fit the model to the training data\n",
        "best_rf_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "best_rf_model_preds = best_rf_model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate the accuracy\n",
        "best_rf_model_accuracy = accuracy_score(y_test, best_rf_model_preds)\n",
        "print(f\"Best Random Forest Model Accuracy: {best_rf_model_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6nYUe9O5USu",
        "outputId": "56a79432-0c1c-443f-aabe-98c9fd34ba71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Model Accuracy: 0.990874524714829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf_model_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8psb26ez5qOK",
        "outputId": "6c758dc3-35e9-4802-9e03-92bf65eaf86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.990874524714829"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming the RandomForestClassifier with the best parameters has already been trained and tested as in the provided code\n",
        "# The model's predictions are stored in best_rf_model_preds and the true labels in y_test\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, best_rf_model_preds)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and f1 score\n",
        "accuracy = accuracy_score(y_test, best_rf_model_preds)\n",
        "precision = precision_score(y_test, best_rf_model_preds, average='weighted')\n",
        "recall = recall_score(y_test, best_rf_model_preds, average='weighted')\n",
        "f1score = f1_score(y_test, best_rf_model_preds, average='weighted')\n",
        "\n",
        "# Print results\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYZIVgviF7Nc",
        "outputId": "d2366626-3a81-4fd8-ec9d-cac051a97df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[44302     0]\n",
            " [  408     0]]\n",
            "\n",
            "Accuracy: 0.990874524714829\n",
            "Precision: 0.9818323237288381\n",
            "Recall: 0.990874524714829\n",
            "F1 Score: 0.986332701072133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Predict probabilities for each class\n",
        "y_pred_proba = best_rf_model.predict_proba(X_test_tfidf)\n",
        "\n",
        "# Assuming y_test contains the true labels for the test data\n",
        "\n",
        "# Calculate log loss\n",
        "logloss = log_loss(y_test, y_pred_proba)\n",
        "\n",
        "print(\"Log Loss:\", logloss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fVDv60bTHya",
        "outputId": "363c6017-40ef-4865-b07a-31f0c263b333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Loss: 0.03860382137994724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression\n",
        "lr_classifier = LogisticRegression(max_iter=1000)\n",
        "lr_classifier.fit(X_train_tfidf, y_train)\n",
        "lr_preds = lr_classifier.predict(X_test_tfidf)\n",
        "lr_accuracy = accuracy_score(y_test, lr_preds)"
      ],
      "metadata": {
        "id": "_Ni7Vx_qUhTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the logistic regression classifier\n",
        "lr_classifier = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# Define the hyperparameters grid\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
        "    'penalty': ['l2'],                     # L2 regularization only for multinomial\n",
        "    'class_weight': [None, 'balanced'],    # Weights associated with classes\n",
        "    'fit_intercept': [True, False],        # Whether to calculate the intercept\n",
        "}\n",
        "\n",
        "# Perform grid search with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=lr_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train a new logistic regression classifier using the best hyperparameters\n",
        "best_lr_classifier = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs', **best_params)\n",
        "best_lr_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set using the best classifier\n",
        "best_lr_preds = best_lr_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "best_lr_accuracy = accuracy_score(y_test, best_lr_preds)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Accuracy with Best Hyperparameters:\", best_lr_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVPmEdWnUzQ3",
        "outputId": "8654dc21-0386-4a26-edbf-c4a8eeaff3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 1, 'class_weight': None, 'fit_intercept': True, 'penalty': 'l2'}\n",
            "Accuracy with Best Hyperparameters: 0.9920152091254753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the logistic regression classifier\n",
        "lr_classifier = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# Fit the classifier with training data\n",
        "lr_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set using lr_classifier\n",
        "lr_preds = lr_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, lr_preds)\n",
        "\n",
        "# Calculate accuracy\n",
        "lr_accuracy = accuracy_score(y_test, lr_preds)\n",
        "\n",
        "# Calculate precision\n",
        "lr_precision = precision_score(y_test, lr_preds, average='weighted')\n",
        "\n",
        "# Calculate recall\n",
        "lr_recall = recall_score(y_test, lr_preds, average='weighted')\n",
        "\n",
        "# Calculate F1 score\n",
        "lr_f1 = f1_score(y_test, lr_preds, average='weighted')\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Accuracy:\", lr_accuracy)\n",
        "print(\"Precision:\", lr_precision)\n",
        "print(\"Recall:\", lr_recall)\n",
        "print(\"F1 Score:\", lr_f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLPCYcWQbaIn",
        "outputId": "e5dab391-ba7b-48f7-c799-9767d37607b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[44249    53]\n",
            " [  304   104]]\n",
            "Accuracy: 0.9920152091254753\n",
            "Precision: 0.9901583576998265\n",
            "Recall: 0.9920152091254753\n",
            "F1 Score: 0.990252874111492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Assuming you have already fitted the lr_classifier with training data and defined X_test_tfidf and y_test\n",
        "\n",
        "# Predict probabilities on the test set\n",
        "lr_probs = lr_classifier.predict_proba(X_test_tfidf)\n",
        "\n",
        "# Calculate log loss\n",
        "lr_log_loss = log_loss(y_test, lr_probs)\n",
        "\n",
        "print(\"Log Loss:\", lr_log_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACzKO9pTdIaL",
        "outputId": "537d5a27-d132-4e10-8b4b-f7be3bb10815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Loss: 0.026057940051724432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hPzlLCXdUCB",
        "outputId": "8a2e7ce3-eb8c-4357-d4e9-bbdae2747fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9920152091254753"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Train SVM\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(X_train_tfidf, y_train)\n",
        "svm_preds = svm_classifier.predict(X_test_tfidf)\n",
        "svm_accuracy = accuracy_score(y_test, svm_preds)"
      ],
      "metadata": {
        "id": "eN0fyXR-diLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Train SVM\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set using svm_classifier\n",
        "svm_preds = svm_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "svm_conf_matrix = confusion_matrix(y_test, svm_preds)\n",
        "\n",
        "# Calculate accuracy\n",
        "svm_accuracy = accuracy_score(y_test, svm_preds)\n",
        "\n",
        "# Calculate precision\n",
        "svm_precision = precision_score(y_test, svm_preds, average='weighted')\n",
        "\n",
        "# Calculate recall\n",
        "svm_recall = recall_score(y_test, svm_preds, average='weighted')\n",
        "\n",
        "# Calculate F1 score\n",
        "svm_f1 = f1_score(y_test, svm_preds, average='weighted')\n",
        "\n",
        "print(\"SVM Confusion Matrix:\\n\", svm_conf_matrix)\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Recall:\", svm_recall)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csLUkfpqhphm",
        "outputId": "8694705a-9bab-43af-f3a9-a311038b643c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Confusion Matrix:\n",
            " [[44273    29]\n",
            " [  342    66]]\n",
            "SVM Accuracy: 0.9917020800715723\n",
            "SVM Precision: 0.9896186973643336\n",
            "SVM Recall: 0.9917020800715723\n",
            "SVM F1 Score: 0.9891349265907705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_accuracy"
      ],
      "metadata": {
        "id": "prvfQ1NblQa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c781f333-052c-4ade-c71c-ba864dcb247f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9917020800715723"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create a pipeline with TruncatedSVD and KNN\n",
        "pipeline = Pipeline([\n",
        "    ('svd', TruncatedSVD(n_components=100)),  # Adjust n_components as needed\n",
        "    ('scaler', StandardScaler()),  # Standardizing after SVD\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=2, n_jobs=-1))  # Use all available cores\n",
        "])\n",
        "\n",
        "# Train the pipeline\n",
        "pipeline.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "knn_preds = pipeline.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "knn_accuracy = accuracy_score(y_test, knn_preds)\n",
        "print(\"KNN Accuracy with SVD:\", knn_accuracy)\n"
      ],
      "metadata": {
        "id": "QONRjExTZ2Kh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d6c0c0-df84-458c-ade8-885ba23e643d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy with SVD: 0.9905166629389398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Assuming you have trained your KNN model and made predictions (knn_preds) on the test set\n",
        "\n",
        "# Calculate Precision\n",
        "precision = precision_score(y_test, knn_preds, average='weighted')\n",
        "\n",
        "# Calculate Recall\n",
        "recall = recall_score(y_test, knn_preds, average='weighted')\n",
        "\n",
        "# Calculate F1 Score\n",
        "f1 = f1_score(y_test, knn_preds, average='weighted')\n",
        "\n",
        "# Calculate Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, knn_preds)\n",
        "\n",
        "# Print the results\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqyyNwRJphSi",
        "outputId": "073d6da4-aacc-4f9c-ea54-0dfa53202594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[44244    58]\n",
            " [  366    42]]\n",
            "Precision: 0.9865776552683461\n",
            "Recall: 0.9905166629389398\n",
            "F1 Score: 0.9876582186532762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Predict probabilities instead of class labels\n",
        "knn_probs = pipeline.predict_proba(X_test_tfidf)  # Note: KNN doesn't have predict_proba, so this will not work\n",
        "\n",
        "# Calculate log loss\n",
        "knn_log_loss = log_loss(y_test, knn_probs)\n",
        "print(\"Log Loss for KNN:\", knn_log_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXtxczk6rM51",
        "outputId": "6cebf10f-5f08-49a0-dc9b-aca2135a433c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Loss for KNN: 0.27391018533064465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the Multinomial Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0],  # Add more values if needed\n",
        "    'fit_prior': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=nb_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Initialize Multinomial Naive Bayes classifier with the best hyperparameters\n",
        "best_nb_classifier = MultinomialNB(**best_params)\n",
        "\n",
        "# Train the best classifier on the entire training set\n",
        "best_nb_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "nb_preds = best_nb_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Accuracy with Best Hyperparameters:\", nb_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUJQ1yvUqXTI",
        "outputId": "7e12636e-7bd1-4f6b-fad7-fbdc7b0d79b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'alpha': 0.5, 'fit_prior': True}\n",
            "Accuracy with Best Hyperparameters: 0.9907179601878774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have made predictions (nb_preds) using your classifier\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, nb_preds)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, nb_preds)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, nb_preds, average='weighted')\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, nb_preds, average='weighted')\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, nb_preds, average='weighted')\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPJqdLglqn-z",
        "outputId": "fb85f6a7-4861-4669-9286-9119c93e1540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[44232    70]\n",
            " [  345    63]]\n",
            "Accuracy: 0.9907179601878774\n",
            "Precision: 0.9875283269429994\n",
            "Recall: 0.9907179601878774\n",
            "F1 Score: 0.9883732063101116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Get probability estimates for each class\n",
        "nb_probs = best_nb_classifier.predict_proba(X_test_tfidf)\n",
        "\n",
        "# Calculate log loss\n",
        "nb_log_loss = log_loss(y_test, nb_probs)\n",
        "\n",
        "print(\"Log Loss with Best Hyperparameters:\", nb_log_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT7FhITysK8t",
        "outputId": "de2bf9bb-7527-49ad-9bf4-157c804fff5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Loss with Best Hyperparameters: 0.02876192589276328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "#python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "\n",
        "# Load English language model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Define a function for preprocessing text with lemmatization\n",
        "def preprocess_text_with_lemmatization(tweet):\n",
        "    # Remove special characters, URLs, and mentions\n",
        "    tweet = re.sub(r'http\\S+|www\\S+|pic.twitter\\S+|@\\S+', '', tweet)\n",
        "    tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n",
        "\n",
        "    # Remove extra spaces and convert to lowercase\n",
        "    tweet = ' '.join(tweet.lower().split())\n",
        "\n",
        "    # Lemmatize the text\n",
        "    lemmatized_tokens = []\n",
        "    doc = nlp(tweet)\n",
        "    for token in doc:\n",
        "        lemmatized_tokens.append(token.lemma_)\n",
        "\n",
        "    # Join lemmatized tokens back into a single string\n",
        "    tweet = ' '.join(lemmatized_tokens)\n",
        "\n",
        "    return tweet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRn1odrfspoQ",
        "outputId": "722ec309-706c-4383-d2f0-c7cda190ce97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iiBjHeNovCjp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}